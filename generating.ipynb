{
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install -U bitsandbytes sentencepiece protobuf",
   "metadata": {
    "id": "Hnwkkpi3yJc7",
    "outputId": "ef1fdb05-1441-4bc9-cdb9-19a27932a584",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "start_time": "2025-05-13T16:37:57.300280Z"
    }
   },
   "id": "Hnwkkpi3yJc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "\n",
    "token_value = userdata.get('hf_token')\n",
    "login(token=token_value)"
   ],
   "metadata": {
    "id": "O4qiKlCqxXP5"
   },
   "id": "O4qiKlCqxXP5",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np\n",
    "\n",
    "def select_best_layer_cosine(activations: np.ndarray, labels: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Визначає найкращий шар нейронної мережі на основі косинусної відстані між активаціями двох класів.\n",
    "\n",
    "    Аналізує активації для кожного шару та обчислює середню косинусну відстань між активаціями\n",
    "    нейтрального класу (labels=0) та спеціального класу (labels=1). Найкращим вважається шар,\n",
    "    де спостерігається найбільше зростання цієї відстані порівняно з попереднім шаром.\n",
    "\n",
    "    Параметри:\n",
    "    ----------\n",
    "    activations : np.ndarray\n",
    "        3D-масив активацій нейронної мережі, форма (n_samples, n_layers, hidden_size).\n",
    "        Містить активації для кожного зразка, шару та нейрона прихованого шару.\n",
    "    labels : np.ndarray\n",
    "        1D-масив міток класів (0 - нейтральний клас, 1 - спеціальний клас).\n",
    "\n",
    "    Повертає:\n",
    "    -------\n",
    "    tuple\n",
    "        best_layer : int\n",
    "            Номер шару з найбільшим приростом косинусної відстані.\n",
    "        layer_distances : dict\n",
    "            Словник із середніми косинусними відстанями для кожного шару {layer: mean_distance}.\n",
    "        layer_deltas : dict\n",
    "            Словник із різницями відстаней між поточним та попереднім шаром {layer: delta}.\n",
    "    \"\"\"\n",
    "    n_samples, n_layers, hidden_size = activations.shape\n",
    "    layer_distances = {}\n",
    "    layer_deltas = {0: 0}\n",
    "    \n",
    "    neutral_acts = activations[labels == 0]\n",
    "    traited_acts = activations[labels == 1]\n",
    "\n",
    "    assert len(neutral_acts) == len(traited_acts), \"Кількість зразків у класах не співпадає\"\n",
    "\n",
    "    # Обчислення середньої косинусної відстані для кожного шару\n",
    "    for layer in range(n_layers):\n",
    "        neutral_layer = neutral_acts[:, layer, :]\n",
    "        traited_layer = traited_acts[:, layer, :]\n",
    "        \n",
    "        distances = cosine_distances(neutral_layer, traited_layer)\n",
    "        mean_distance = np.mean(np.diag(distances))\n",
    "        layer_distances[layer] = mean_distance\n",
    "\n",
    "    # Обчислення дельт (різниць між шарами)\n",
    "    for layer in range(1, n_layers):\n",
    "        delta = layer_distances[layer] - layer_distances[layer-1]\n",
    "        layer_deltas[layer] = delta\n",
    "\n",
    "    best_layer = max(layer_deltas, key=layer_deltas.get)\n",
    "    return best_layer, layer_distances, layer_deltas"
   ],
   "metadata": {
    "id": "NP3qsPP3w-hE",
    "ExecuteTime": {
     "end_time": "2025-05-14T10:18:47.400636Z",
     "start_time": "2025-05-14T10:18:46.130685Z"
    }
   },
   "id": "NP3qsPP3w-hE",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:18:47.482521Z",
     "start_time": "2025-05-14T10:18:47.400636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def select_best_layer_logreg(activations: np.ndarray, labels: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Визначає найкращий шар нейронної мережі на основі AUC-ROC логістичної регресії.\n",
    "\n",
    "    Для кожного шару активацій навчає модель логістичної регресії та обчислює AUC-ROC,\n",
    "    щоб оцінити, наскільки добре активації шару лінійно розділяють два класи. \n",
    "    Найкращим вважається шар із найвищим значенням AUC-ROC.\n",
    "\n",
    "    Параметри:\n",
    "    ----------\n",
    "    activations : np.ndarray\n",
    "        3D-масив активацій нейронної мережі, форма (n_samples, n_layers, hidden_size).\n",
    "        Містить активації для кожного зразка, шару та нейрона прихованого шару.\n",
    "    labels : np.ndarray\n",
    "        1D-масив міток класів (0 - перший клас, 1 - другий клас).\n",
    "\n",
    "    Повертає:\n",
    "    -------\n",
    "    tuple\n",
    "        best_layer : int\n",
    "            Номер шару з найвищим значенням AUC-ROC.\n",
    "        layer_aucs : dict\n",
    "            Словник із значеннями AUC-ROC для кожного шару {layer: auc_score}.\n",
    "    \"\"\"\n",
    "    n_samples, n_layers, hidden_size = activations.shape\n",
    "    layer_aucs = {}\n",
    "\n",
    "    for layer in range(n_layers):\n",
    "        X_layer = activations[:, layer, :]\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "        clf.fit(X_layer, labels)\n",
    "\n",
    "        probs = clf.predict_proba(X_layer)[:, 1]\n",
    "        pred = clf.predict(X_layer)\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "        layer_aucs[layer] = auc\n",
    "\n",
    "    best_layer = max(layer_aucs, key=layer_aucs.get)\n",
    "    return best_layer, layer_aucs"
   ],
   "id": "469ec117a9a1bd60",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def collect_activations(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset_path: str,\n",
    "    model_type: str = \"llama\",\n",
    "    max_samples: int = None,\n",
    "    batch_size: int = 8\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Збирає активації з прихованих шарів моделі для набору даних з обробкою батчами.\n",
    "\n",
    "    Параметри:\n",
    "    ----------\n",
    "    model : PreTrainedModel\n",
    "        Модель трансформера для генерації та отримання активацій.\n",
    "    tokenizer : PreTrainedTokenizer\n",
    "        Токенізатор для обробки вхідних текстів.\n",
    "    dataset_path : str\n",
    "        Шлях до JSON-файлу з датасетом.\n",
    "    model_type : str, optional\n",
    "        Тип моделі (за замовчуванням \"llama\").\n",
    "    max_samples : int, optional\n",
    "        Максимальна кількість зразків для обробки.\n",
    "    batch_size : int, optional\n",
    "        Розмір батчу.\n",
    "\n",
    "    Повертає:\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray]\n",
    "        all_activations : np.ndarray\n",
    "            3D-масив активацій форми (n_samples, n_layers, hidden_size).\n",
    "        all_labels : np.ndarray\n",
    "            1D-масив міток (0 - нейтральний, 1 - спеціальний).\n",
    "    \"\"\"\n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if max_samples is not None:\n",
    "        data = data[:max_samples]\n",
    "\n",
    "    prompts = []\n",
    "    labels = []\n",
    "\n",
    "    for sample in data:\n",
    "        prompt_pair = sample[\"prompts\"][model_type]\n",
    "        prompts.extend([prompt_pair[\"neutral\"], prompt_pair[\"traited\"]])\n",
    "        labels.extend([0, 1])\n",
    "\n",
    "    all_activations = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Обробка батчів\"):\n",
    "        batch_prompts = prompts[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "\n",
    "        inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "        hidden_states = torch.stack(outputs.hidden_states[1:])  # (n_layers, batch, seq_len, hidden_size)\n",
    "        attention_mask = inputs.attention_mask[:, None, :, None]  # (batch, 1, seq_len, 1)\n",
    "        attention_mask = attention_mask.permute(1, 0, 2, 3)  # (1, batch, seq_len, 1)\n",
    "        masked = hidden_states * attention_mask  # (n_layers, batch, seq_len, hidden_size)\n",
    "        sum_states = masked.sum(dim=2)  # (n_layers, batch, hidden_size)\n",
    "        sum_mask = attention_mask.sum(dim=2)  # (1, batch, 1)\n",
    "        layer_activations = (sum_states / sum_mask).permute(1, 0, 2).cpu().numpy()  # (batch, n_layers, hidden_size)\n",
    "\n",
    "\n",
    "        all_activations.append(layer_activations)\n",
    "        all_labels.extend(batch_labels)\n",
    "\n",
    "    all_activations = np.concatenate(all_activations, axis=0)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    return all_activations, all_labels"
   ],
   "metadata": {
    "id": "j4yIcr5T4PbY",
    "ExecuteTime": {
     "end_time": "2025-05-14T10:18:50.434512Z",
     "start_time": "2025-05-14T10:18:47.737580Z"
    }
   },
   "id": "j4yIcr5T4PbY",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import torch\n",
    "from typing import Optional\n",
    "\n",
    "def load_model(model_name: str, bnb_config: Optional[BitsAndBytesConfig] = None):\n",
    "    \"\"\"\n",
    "    Завантажує модель (LLaMA, Mistral або Flan-T5) з Hugging Face Hub з підтримкою 4/8-бітної квантізації.\n",
    "\n",
    "    Параметри:\n",
    "        model_name (str): Назва моделі на Hugging Face Hub.\n",
    "        bnb_config (BitsAndBytesConfig, optional): Об'єкт конфігурації квантізації BitsAndBytes. \n",
    "                                                   Якщо None — модель буде завантажена без квантізації або у float16.\n",
    "\n",
    "    Повертає:\n",
    "        tuple: (model, tokenizer) — завантажена модель та відповідний токенізатор.\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    is_seq2seq = \"flan-t5\" in model_name.lower() or \"t5\" in model_name.lower()\n",
    "\n",
    "    if bnb_config is not None:\n",
    "        model_class = AutoModelForSeq2SeqLM if is_seq2seq else AutoModelForCausalLM\n",
    "        model = model_class.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"auto\",\n",
    "            output_hidden_states=True,\n",
    "            return_dict_in_generate=True\n",
    "        )\n",
    "    else:\n",
    "        model_class = AutoModelForSeq2SeqLM if is_seq2seq else AutoModelForCausalLM\n",
    "        model = model_class.from_pretrained(\n",
    "            model_name,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            output_hidden_states=True,\n",
    "            return_dict_in_generate=True\n",
    "        )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token if tokenizer.pad_token is None else tokenizer.pad_token\n",
    "    tokenizer.padding_side = \"left\"\n",
    "\n",
    "    model.eval()\n",
    "    return model, tokenizer"
   ],
   "metadata": {
    "id": "XHqLO9mpxKmQ",
    "outputId": "75458f4a-d71e-44c8-9b70-0248f9f0d750",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "ExecuteTime": {
     "end_time": "2025-05-14T10:18:52.004562Z",
     "start_time": "2025-05-14T10:18:50.436784Z"
    }
   },
   "id": "XHqLO9mpxKmQ",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:18:52.018996Z",
     "start_time": "2025-05-14T10:18:52.014577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")"
   ],
   "id": "858a56b8ebecc16f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:34:07.438584Z",
     "start_time": "2025-05-14T09:33:48.337109Z"
    }
   },
   "cell_type": "code",
   "source": "llama_model, llama_tokenizer = load_model(\"meta-llama/Llama-2-7b-hf\", bnb_config)",
   "id": "739d4739cc3d9a28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "404f2218255c4adea60987f678e04c64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9\n",
    "}\n",
    "\n",
    "all_activations, all_labels = collect_activations(llama_model, llama_tokenizer, \"trait_combined_dataset.json\", \"llama\", batch_size=8)"
   ],
   "metadata": {
    "id": "4D5GVP1exT6b",
    "ExecuteTime": {
     "end_time": "2025-05-14T09:51:16.545489Z",
     "start_time": "2025-05-14T09:34:07.448348Z"
    }
   },
   "id": "4D5GVP1exT6b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обробка батчів: 100%|██████████| 2275/2275 [16:48<00:00,  2.26it/s] \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:51:16.674766Z",
     "start_time": "2025-05-14T09:51:16.655921Z"
    }
   },
   "cell_type": "code",
   "source": "all_activations.shape, all_labels.shape",
   "id": "f13a72aabd5b66fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18200, 32, 4096), (18200,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "best_layer, layer_distances, layers_deltas = select_best_layer_cosine(all_activations, all_labels)\n",
    "\n",
    "print(\"Layers scores:\")\n",
    "for layer, distance in layer_distances.items():\n",
    "    print(f\"Layer {layer}: score = {distance:.4f}, delta = {layers_deltas[layer]:.4f}\")\n",
    "\n",
    "print(f\"\\nBest layer: {best_layer} with score = {layer_distances[best_layer]:.4f} delta = {layers_deltas[best_layer]:.4f}\")"
   ],
   "metadata": {
    "id": "XSnwaApF4-nR",
    "ExecuteTime": {
     "end_time": "2025-05-14T09:54:29.874152Z",
     "start_time": "2025-05-14T09:51:50.281900Z"
    }
   },
   "id": "XSnwaApF4-nR",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers scores:\n",
      "Layer 0: score = 0.0142, delta = 0.0000\n",
      "Layer 1: score = 0.0001, delta = -0.0141\n",
      "Layer 2: score = 0.0002, delta = 0.0001\n",
      "Layer 3: score = 0.0004, delta = 0.0002\n",
      "Layer 4: score = 0.0006, delta = 0.0002\n",
      "Layer 5: score = 0.0008, delta = 0.0003\n",
      "Layer 6: score = 0.0012, delta = 0.0004\n",
      "Layer 7: score = 0.0017, delta = 0.0005\n",
      "Layer 8: score = 0.0022, delta = 0.0005\n",
      "Layer 9: score = 0.0028, delta = 0.0005\n",
      "Layer 10: score = 0.0035, delta = 0.0008\n",
      "Layer 11: score = 0.0043, delta = 0.0008\n",
      "Layer 12: score = 0.0053, delta = 0.0010\n",
      "Layer 13: score = 0.0069, delta = 0.0017\n",
      "Layer 14: score = 0.0081, delta = 0.0011\n",
      "Layer 15: score = 0.0107, delta = 0.0027\n",
      "Layer 16: score = 0.0163, delta = 0.0056\n",
      "Layer 17: score = 0.0197, delta = 0.0034\n",
      "Layer 18: score = 0.0259, delta = 0.0061\n",
      "Layer 19: score = 0.0323, delta = 0.0064\n",
      "Layer 20: score = 0.0425, delta = 0.0102\n",
      "Layer 21: score = 0.0492, delta = 0.0067\n",
      "Layer 22: score = 0.0598, delta = 0.0107\n",
      "Layer 23: score = 0.0632, delta = 0.0033\n",
      "Layer 24: score = 0.0692, delta = 0.0060\n",
      "Layer 25: score = 0.0721, delta = 0.0029\n",
      "Layer 26: score = 0.0790, delta = 0.0069\n",
      "Layer 27: score = 0.0818, delta = 0.0028\n",
      "Layer 28: score = 0.0897, delta = 0.0079\n",
      "Layer 29: score = 0.0966, delta = 0.0069\n",
      "Layer 30: score = 0.1139, delta = 0.0173\n",
      "Layer 31: score = 0.2247, delta = 0.1108\n",
      "\n",
      "Best layer: 31 with score = 0.2247 delta = 0.1108\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T09:56:55.954153Z",
     "start_time": "2025-05-14T09:54:30.158769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_layer, layer_aucs = select_best_layer_logreg(all_activations, all_labels)\n",
    "\n",
    "print(\"Layers scores:\")\n",
    "for layer, score in layer_aucs.items():\n",
    "    print(f\"Layer {layer}: score = {score:.4f}\")\n",
    "\n",
    "print(f\"\\nBest layer: {best_layer} with score = {layer_aucs[best_layer]:.4f}\")"
   ],
   "id": "d43488123e2842be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layers scores:\n",
      "Layer 0: score = 0.9998\n",
      "Layer 1: score = 1.0000\n",
      "Layer 2: score = 1.0000\n",
      "Layer 3: score = 1.0000\n",
      "Layer 4: score = 1.0000\n",
      "Layer 5: score = 1.0000\n",
      "Layer 6: score = 1.0000\n",
      "Layer 7: score = 1.0000\n",
      "Layer 8: score = 1.0000\n",
      "Layer 9: score = 1.0000\n",
      "Layer 10: score = 1.0000\n",
      "Layer 11: score = 1.0000\n",
      "Layer 12: score = 1.0000\n",
      "Layer 13: score = 1.0000\n",
      "Layer 14: score = 1.0000\n",
      "Layer 15: score = 1.0000\n",
      "Layer 16: score = 1.0000\n",
      "Layer 17: score = 1.0000\n",
      "Layer 18: score = 1.0000\n",
      "Layer 19: score = 1.0000\n",
      "Layer 20: score = 1.0000\n",
      "Layer 21: score = 1.0000\n",
      "Layer 22: score = 1.0000\n",
      "Layer 23: score = 1.0000\n",
      "Layer 24: score = 1.0000\n",
      "Layer 25: score = 1.0000\n",
      "Layer 26: score = 1.0000\n",
      "Layer 27: score = 1.0000\n",
      "Layer 28: score = 1.0000\n",
      "Layer 29: score = 1.0000\n",
      "Layer 30: score = 1.0000\n",
      "Layer 31: score = 1.0000\n",
      "\n",
      "Best layer: 3 with score = 1.0000\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:19:15.319563Z",
     "start_time": "2025-05-14T10:18:54.165027Z"
    }
   },
   "cell_type": "code",
   "source": "mistral_model, mistral_tokenizer = load_model(\"mistralai/Mistral-7B-v0.3\", bnb_config)",
   "id": "5d4f3181839e2b87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "672655a4b7cb4899b9f23d371cd61267"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "691e78e152db4fd3822ec6f4b989e79f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/137k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9be54508bcd4452a95a5e54fed2c8d18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "780bae9eb6724730a63243ec75e4edf4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0872fbfbeeb4bf98a9372d9d07ebe9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5476032b780544e482aa22058ef1a763"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "4D5GVP1exT6b",
    "ExecuteTime": {
     "end_time": "2025-05-14T10:35:28.871091Z",
     "start_time": "2025-05-14T10:19:25.813756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9\n",
    "}\n",
    "\n",
    "all_activations, all_labels = collect_activations(mistral_model, mistral_tokenizer, \"trait_combined_dataset.json\", \"mistral\")"
   ],
   "id": "69b1214420e4a9ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обробка батчів: 100%|██████████| 2275/2275 [15:48<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:35:29.016882Z",
     "start_time": "2025-05-14T10:35:28.957278Z"
    }
   },
   "cell_type": "code",
   "source": "all_activations.shape, all_labels.shape",
   "id": "7f70d582b4a911c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18200, 32, 4096), (18200,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "XSnwaApF4-nR",
    "ExecuteTime": {
     "end_time": "2025-05-14T10:38:47.020371Z",
     "start_time": "2025-05-14T10:35:29.332785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_layer, layer_distances, layers_deltas = select_best_layer_cosine(all_activations, all_labels)\n",
    "\n",
    "print(\"Layers scores:\")\n",
    "for layer, distance in layer_distances.items():\n",
    "    print(f\"Layer {layer}: score = {distance:.4f}, delta = {layers_deltas[layer]:.4f}\")\n",
    "\n",
    "print(f\"\\nBest layer: {best_layer} with score = {layer_distances[best_layer]:.4f} delta = {layers_deltas[best_layer]:.4f}\")"
   ],
   "id": "f7ab50c89c8b9640",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers scores:\n",
      "Layer 0: score = 0.1329, delta = 0.0000\n",
      "Layer 1: score = 0.0200, delta = -0.1129\n",
      "Layer 2: score = 0.0199, delta = -0.0000\n",
      "Layer 3: score = 0.0200, delta = 0.0001\n",
      "Layer 4: score = 0.0202, delta = 0.0002\n",
      "Layer 5: score = 0.0209, delta = 0.0007\n",
      "Layer 6: score = 0.0215, delta = 0.0006\n",
      "Layer 7: score = 0.0226, delta = 0.0011\n",
      "Layer 8: score = 0.0230, delta = 0.0004\n",
      "Layer 9: score = 0.0245, delta = 0.0015\n",
      "Layer 10: score = 0.0250, delta = 0.0005\n",
      "Layer 11: score = 0.0260, delta = 0.0010\n",
      "Layer 12: score = 0.0278, delta = 0.0018\n",
      "Layer 13: score = 0.0279, delta = 0.0002\n",
      "Layer 14: score = 0.0294, delta = 0.0014\n",
      "Layer 15: score = 0.0333, delta = 0.0039\n",
      "Layer 16: score = 0.0389, delta = 0.0056\n",
      "Layer 17: score = 0.0408, delta = 0.0019\n",
      "Layer 18: score = 0.0502, delta = 0.0094\n",
      "Layer 19: score = 0.0589, delta = 0.0087\n",
      "Layer 20: score = 0.0675, delta = 0.0086\n",
      "Layer 21: score = 0.0715, delta = 0.0040\n",
      "Layer 22: score = 0.0733, delta = 0.0018\n",
      "Layer 23: score = 0.0754, delta = 0.0021\n",
      "Layer 24: score = 0.0782, delta = 0.0028\n",
      "Layer 25: score = 0.0801, delta = 0.0019\n",
      "Layer 26: score = 0.0866, delta = 0.0065\n",
      "Layer 27: score = 0.0933, delta = 0.0066\n",
      "Layer 28: score = 0.1124, delta = 0.0191\n",
      "Layer 29: score = 0.1306, delta = 0.0183\n",
      "Layer 30: score = 0.1628, delta = 0.0322\n",
      "Layer 31: score = 0.2792, delta = 0.1164\n",
      "\n",
      "Best layer: 31 with score = 0.2792 delta = 0.1164\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:40:56.605903Z",
     "start_time": "2025-05-14T10:38:47.285671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_layer, layer_aucs = select_best_layer_logreg(all_activations, all_labels)\n",
    "\n",
    "print(\"Layers scores:\")\n",
    "for layer, score in layer_aucs.items():\n",
    "    print(f\"Layer {layer}: score = {score:.4f}\")\n",
    "\n",
    "print(f\"\\nBest layer: {best_layer} with score = {layer_aucs[best_layer]:.4f}\")"
   ],
   "id": "79c4bce1ecfbde8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers scores:\n",
      "Layer 0: score = 0.9860\n",
      "Layer 1: score = 0.9954\n",
      "Layer 2: score = 0.9991\n",
      "Layer 3: score = 1.0000\n",
      "Layer 4: score = 1.0000\n",
      "Layer 5: score = 1.0000\n",
      "Layer 6: score = 1.0000\n",
      "Layer 7: score = 1.0000\n",
      "Layer 8: score = 1.0000\n",
      "Layer 9: score = 1.0000\n",
      "Layer 10: score = 1.0000\n",
      "Layer 11: score = 1.0000\n",
      "Layer 12: score = 1.0000\n",
      "Layer 13: score = 1.0000\n",
      "Layer 14: score = 1.0000\n",
      "Layer 15: score = 1.0000\n",
      "Layer 16: score = 1.0000\n",
      "Layer 17: score = 1.0000\n",
      "Layer 18: score = 1.0000\n",
      "Layer 19: score = 1.0000\n",
      "Layer 20: score = 1.0000\n",
      "Layer 21: score = 1.0000\n",
      "Layer 22: score = 1.0000\n",
      "Layer 23: score = 1.0000\n",
      "Layer 24: score = 1.0000\n",
      "Layer 25: score = 1.0000\n",
      "Layer 26: score = 1.0000\n",
      "Layer 27: score = 1.0000\n",
      "Layer 28: score = 1.0000\n",
      "Layer 29: score = 1.0000\n",
      "Layer 30: score = 1.0000\n",
      "Layer 31: score = 1.0000\n",
      "\n",
      "Best layer: 8 with score = 1.0000\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "t5_model, t5_tokenizer = load_model(\"google/flan-t5-xl\", bnb_config)",
   "id": "910fa037928e7901"
  },
  {
   "metadata": {
    "id": "4D5GVP1exT6b",
    "jupyter": {},
    "ExecuteTime": {
     "end_time": "2025-05-14T10:18:05.004363400Z",
     "start_time": "2025-05-14T08:50:40.968542Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обробка прикладів:  20%|██        | 1828/9100 [05:22<22:29,  5.39it/s]"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 1.1,\n",
    "    \"top_p\": 0.99,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "all_activations, all_labels = collect_activations(t5_model, t5_tokenizer, \"trait_combined_dataset.json\", \"flan_t5\")"
   ],
   "id": "f6136f635d6fd1bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:18:05.004363400Z",
     "start_time": "2025-05-14T08:28:08.044058Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 32, 4096), (2,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10,
   "source": "all_activations.shape, all_labels.shape",
   "id": "922914eacf916729"
  },
  {
   "metadata": {
    "id": "XSnwaApF4-nR",
    "ExecuteTime": {
     "end_time": "2025-05-14T10:18:05.004363400Z",
     "start_time": "2025-05-14T08:28:41.104018Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers scores:\n",
      "Layer 0: score = 0.0153, delta = 0.0000\n",
      "Layer 1: score = 0.0001, delta = -0.0152\n",
      "Layer 2: score = 0.0002, delta = 0.0001\n",
      "Layer 3: score = 0.0003, delta = 0.0001\n",
      "Layer 4: score = 0.0005, delta = 0.0002\n",
      "Layer 5: score = 0.0008, delta = 0.0002\n",
      "Layer 6: score = 0.0011, delta = 0.0003\n",
      "Layer 7: score = 0.0017, delta = 0.0006\n",
      "Layer 8: score = 0.0021, delta = 0.0005\n",
      "Layer 9: score = 0.0027, delta = 0.0006\n",
      "Layer 10: score = 0.0033, delta = 0.0006\n",
      "Layer 11: score = 0.0041, delta = 0.0009\n",
      "Layer 12: score = 0.0050, delta = 0.0009\n",
      "Layer 13: score = 0.0066, delta = 0.0016\n",
      "Layer 14: score = 0.0080, delta = 0.0014\n",
      "Layer 15: score = 0.0104, delta = 0.0023\n",
      "Layer 16: score = 0.0160, delta = 0.0057\n",
      "Layer 17: score = 0.0197, delta = 0.0037\n",
      "Layer 18: score = 0.0268, delta = 0.0071\n",
      "Layer 19: score = 0.0342, delta = 0.0074\n",
      "Layer 20: score = 0.0464, delta = 0.0122\n",
      "Layer 21: score = 0.0542, delta = 0.0078\n",
      "Layer 22: score = 0.0681, delta = 0.0139\n",
      "Layer 23: score = 0.0726, delta = 0.0045\n",
      "Layer 24: score = 0.0813, delta = 0.0087\n",
      "Layer 25: score = 0.0854, delta = 0.0041\n",
      "Layer 26: score = 0.0931, delta = 0.0077\n",
      "Layer 27: score = 0.0973, delta = 0.0042\n",
      "Layer 28: score = 0.1076, delta = 0.0104\n",
      "Layer 29: score = 0.1181, delta = 0.0105\n",
      "Layer 30: score = 0.1553, delta = 0.0372\n",
      "Layer 31: score = 0.2830, delta = 0.1277\n",
      "\n",
      "Best layer: 31 with score = 0.2830 delta = 0.1277\n"
     ]
    }
   ],
   "execution_count": 13,
   "source": [
    "best_layer, layer_distances, layers_deltas = select_best_layer_cosine(all_activations, all_labels)\n",
    "\n",
    "print(\"Layers scores:\")\n",
    "for layer, distance in layer_distances.items():\n",
    "    print(f\"Layer {layer}: score = {distance:.4f}, delta = {layers_deltas[layer]:.4f}\")\n",
    "\n",
    "print(f\"\\nBest layer: {best_layer} with score = {layer_distances[best_layer]:.4f} delta = {layers_deltas[best_layer]:.4f}\")"
   ],
   "id": "69db6ef2a61e3792"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_layer, layer_aucs = select_best_layer_logreg(all_activations, all_labels)\n",
    "\n",
    "print(\"Layers scores:\")\n",
    "for layer, score in layer_aucs.items():\n",
    "    print(f\"Layer {layer}: score = {score:.4f}\")\n",
    "\n",
    "print(f\"\\nBest layer: {best_layer} with score = {layer_aucs[best_layer]:.4f}\")"
   ],
   "id": "8f5fd51a04e1e307",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aaddfd658cf40df4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
