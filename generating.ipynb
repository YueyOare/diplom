{
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install -U bitsandbytes sentencepiece protobuf",
   "metadata": {
    "id": "Hnwkkpi3yJc7",
    "outputId": "ef1fdb05-1441-4bc9-cdb9-19a27932a584",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "start_time": "2025-05-13T16:37:57.300280Z"
    }
   },
   "id": "Hnwkkpi3yJc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "\n",
    "token_value = userdata.get('hf_token')\n",
    "login(token=token_value)"
   ],
   "metadata": {
    "id": "O4qiKlCqxXP5"
   },
   "id": "O4qiKlCqxXP5",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np\n",
    "\n",
    "def select_best_layer(activations: np.ndarray, labels: np.ndarray):\n",
    "    \"\"\"\n",
    "    Выбирает слой с наибольшим изменением косинусного расстояния между нейтральными и traited активациями\n",
    "    по сравнению с предыдущим слоем.\n",
    "\n",
    "    Параметры:\n",
    "        activations: np.ndarray, форма (n_samples, n_layers, hidden_size)\n",
    "        labels: np.ndarray, форма (n_samples,), где 0 - neutral, 1 - traited\n",
    "\n",
    "    Возвращает:\n",
    "        best_layer: индекс слоя с максимальным изменением косинусного расстояния\n",
    "        layer_deltas: словарь {layer_index: изменение_расстояния}\n",
    "        layer_distances: словарь {layer_index: абсолютное_расстояние}\n",
    "    \"\"\"\n",
    "    n_samples, n_layers, hidden_size = activations.shape\n",
    "    layer_distances = {}\n",
    "    layer_deltas = {0: 0}\n",
    "    \n",
    "    # Разделяем активации на нейтральные и traited\n",
    "    neutral_acts = activations[labels == 0]\n",
    "    traited_acts = activations[labels == 1]\n",
    "\n",
    "    # Проверка, что у нас есть пары для сравнения\n",
    "    assert len(neutral_acts) == len(traited_acts), \"Количество neutral и traited примеров должно совпадать\"\n",
    "\n",
    "    # Вычисляем расстояния для всех слоев\n",
    "    for layer in range(n_layers):\n",
    "        neutral_layer = neutral_acts[:, layer, :]\n",
    "        traited_layer = traited_acts[:, layer, :]\n",
    "        \n",
    "        distances = cosine_distances(neutral_layer, traited_layer)\n",
    "        mean_distance = np.mean(np.diag(distances))\n",
    "        layer_distances[layer] = mean_distance\n",
    "\n",
    "    # Вычисляем изменения расстояний между слоями\n",
    "    for layer in range(1, n_layers):\n",
    "        delta = layer_distances[layer] - layer_distances[layer-1]\n",
    "        layer_deltas[layer] = delta\n",
    "\n",
    "    # Находим слой с максимальным изменением\n",
    "    best_layer = max(layer_deltas, key=layer_deltas.get)\n",
    "    \n",
    "    return best_layer, layer_distances, layer_deltas"
   ],
   "metadata": {
    "id": "NP3qsPP3w-hE",
    "ExecuteTime": {
     "end_time": "2025-05-13T17:54:25.279849Z",
     "start_time": "2025-05-13T17:54:24.139113Z"
    }
   },
   "id": "NP3qsPP3w-hE",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:29:38.079579Z",
     "start_time": "2025-05-13T17:29:38.071676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# import numpy as np\n",
    "# \n",
    "# def select_best_layer(activations: np.ndarray, labels: np.ndarray):\n",
    "# \n",
    "#     n_samples, n_layers, hidden_size = activations.shape\n",
    "#     layer_aucs = {}\n",
    "# \n",
    "#     # Перебір по кожному шару\n",
    "#     for layer in range(n_layers):\n",
    "#         # Формуємо матрицю X для поточного шару: (n_samples, hidden_size)\n",
    "#         X_layer = activations[:, layer, :]\n",
    "# \n",
    "#         # Навчання логістичної регресії\n",
    "#         clf = LogisticRegression(max_iter=1000)\n",
    "#         clf.fit(X_layer, labels)\n",
    "# \n",
    "#         # Прогнозування й обчислення AUC\n",
    "#         probs = clf.predict_proba(X_layer)[:, 1]\n",
    "#         auc = roc_auc_score(labels, probs)\n",
    "#         layer_aucs[layer] = auc\n",
    "# \n",
    "#     # Вибір шару з максимальною AUC\n",
    "#     best_layer = max(layer_aucs, key=layer_aucs.get)\n",
    "#     return best_layer, layer_aucs"
   ],
   "id": "469ec117a9a1bd60",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "\n",
    "def collect_activations_batched(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset_path: str,\n",
    "    generation_args: dict,\n",
    "    model_type: str = \"llama\",  # \"llama\", \"mistral\" или \"flan_t5\"\n",
    "    batch_size: int = 8,\n",
    "    max_samples: int = None\n",
    ") -> Tuple[np.ndarray, np.ndarray, list]:\n",
    "    \"\"\"\n",
    "    Собирает активации, метки и ответы модели для всех промптов в датасете\n",
    "    \n",
    "    Параметры:\n",
    "        model_type: тип модели (\"llama\", \"mistral\" или \"flan_t5\")\n",
    "    \n",
    "    Возвращает:\n",
    "        all_activations: np.ndarray форма (n_samples, n_layers, hidden_size)\n",
    "        all_labels: np.ndarray форма (n_samples,)\n",
    "        all_responses: list[dict] список ответов модели с дополнительной информацией\n",
    "    \"\"\"\n",
    "    # Загрузка датасета\n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if max_samples is not None:\n",
    "        data = data[:max_samples]\n",
    "    \n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    all_activations = []\n",
    "    all_labels = []\n",
    "    all_responses = []\n",
    "    batch_prompts = []\n",
    "    batch_labels = []\n",
    "    batch_samples = []  # Для хранения исходных данных\n",
    "\n",
    "    # Подготовка всех промптов и меток\n",
    "    for sample in tqdm(data, desc=\"Preparing prompts\"):\n",
    "        # Выбираем нужный формат промпта в зависимости от модели\n",
    "        prompts = sample[\"prompts\"][model_type]\n",
    "        \n",
    "        # Добавляем оба варианта (neutral и traited)\n",
    "        batch_prompts.extend([prompts[\"neutral\"], prompts[\"traited\"]])\n",
    "        batch_labels.extend([0, 1])  # 0 для neutral, 1 для traited\n",
    "        batch_samples.extend([sample, sample])\n",
    "\n",
    "    # Обработка батчами\n",
    "    for i in tqdm(range(0, len(batch_prompts), batch_size), desc=\"Processing batches\"):\n",
    "        current_batch = batch_prompts[i:i+batch_size]\n",
    "        current_labels = batch_labels[i:i+batch_size]\n",
    "        current_samples = batch_samples[i:i+batch_size]\n",
    "\n",
    "        # Токенизация батча\n",
    "        inputs = tokenizer(\n",
    "            current_batch, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            return_token_type_ids=False\n",
    "        ).to(model.device)\n",
    "\n",
    "        # Получение скрытых состояний и генерация ответов\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            generated_ids = model.generate(\n",
    "                **inputs,\n",
    "                **generation_args,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "        # Декодирование ответов\n",
    "        responses = [\n",
    "            {\n",
    "                \"model_type\": model_type,\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": tokenizer.decode(ids, skip_special_tokens=True),\n",
    "                \"label\": label,\n",
    "                \"trait\": sample[\"trait\"],\n",
    "                \"instruction\": sample[\"alpaca_instruction\"],\n",
    "                \"input\": sample[\"alpaca_input\"],\n",
    "                \"is_neutral\": label == 0,\n",
    "                \"system_prompt\": sample[\"system_prompt\"] if label == 1 else None\n",
    "            }\n",
    "            for prompt, ids, label, sample in zip(\n",
    "                current_batch,\n",
    "                generated_ids,\n",
    "                current_labels,\n",
    "                current_samples\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Для FLAN-T5 удаляем префикс \"Output:\" из ответа\n",
    "        if model_type == \"flan_t5\":\n",
    "            for r in responses:\n",
    "                r[\"response\"] = r[\"response\"].replace(\"Output:\", \"\").strip()\n",
    "        \n",
    "        all_responses.extend(responses)\n",
    "\n",
    "        # Сбор активаций\n",
    "        hidden_states = torch.stack(outputs.hidden_states[1:])  # Пропускаем embedding слой\n",
    "        attention_mask = inputs.attention_mask.unsqueeze(0).unsqueeze(-1)\n",
    "        sum_states = (hidden_states * attention_mask).sum(dim=2)\n",
    "        sum_mask = attention_mask.sum(dim=2)\n",
    "        layer_activations = sum_states / sum_mask\n",
    "        batch_activations = layer_activations.permute(1, 0, 2).cpu().numpy()\n",
    "\n",
    "        all_activations.append(batch_activations)\n",
    "        all_labels.extend(current_labels)\n",
    "\n",
    "    # Объединение всех батчей\n",
    "    all_activations = np.concatenate(all_activations, axis=0)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    return all_activations, all_labels, all_responses"
   ],
   "metadata": {
    "id": "j4yIcr5T4PbY",
    "ExecuteTime": {
     "end_time": "2025-05-13T17:54:37.121740Z",
     "start_time": "2025-05-13T17:54:34.175423Z"
    }
   },
   "id": "j4yIcr5T4PbY",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "def load_llama8bit(model_name: str = \"meta-llama/Llama-2-7b-hf\"):\n",
    "    \"\"\"\n",
    "    Завантажує квантизовану в 8-bit модель LLaMA та токенізатор.\n",
    "\n",
    "    Параметри:\n",
    "        model_name: назва моделі на Hugging Face Hub\n",
    "\n",
    "    Повертає:\n",
    "        model: LlamaForCausalLM з output_hidden_states=True\n",
    "        tokenizer: LlamaTokenizer\n",
    "    \"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    model.eval()\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_llama8bit()"
   ],
   "metadata": {
    "id": "XHqLO9mpxKmQ",
    "outputId": "75458f4a-d71e-44c8-9b70-0248f9f0d750",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "ExecuteTime": {
     "end_time": "2025-05-13T17:55:02.357364Z",
     "start_time": "2025-05-13T17:54:37.126918Z"
    }
   },
   "id": "XHqLO9mpxKmQ",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8220a839f7449bc89dd5f6e78445e01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9\n",
    "}\n",
    "\n",
    "all_activations, all_labels, all_responses = collect_activations_batched(\n",
    "    model, tokenizer, \"trait_combined_dataset.json\",\n",
    "    generation_args, batch_size=8\n",
    ")"
   ],
   "metadata": {
    "id": "4D5GVP1exT6b",
    "ExecuteTime": {
     "end_time": "2025-05-13T18:48:32.173603400Z",
     "start_time": "2025-05-13T18:32:54.891585Z"
    }
   },
   "id": "4D5GVP1exT6b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing prompts: 100%|██████████| 9100/9100 [00:00<00:00, 1187448.79it/s]\n",
      "Processing batches:   0%|          | 6/2275 [15:37<98:26:15, 156.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      1\u001B[39m generation_args = {\n\u001B[32m      2\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmax_new_tokens\u001B[39m\u001B[33m\"\u001B[39m: \u001B[32m512\u001B[39m,\n\u001B[32m      3\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdo_sample\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m      4\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtemperature\u001B[39m\u001B[33m\"\u001B[39m: \u001B[32m0.7\u001B[39m,\n\u001B[32m      5\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtop_p\u001B[39m\u001B[33m\"\u001B[39m: \u001B[32m0.9\u001B[39m\n\u001B[32m      6\u001B[39m }\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m all_activations, all_labels, all_responses = \u001B[43mcollect_activations_batched\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtrait_combined_dataset.json\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgeneration_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m8\u001B[39;49m\n\u001B[32m     11\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 73\u001B[39m, in \u001B[36mcollect_activations_batched\u001B[39m\u001B[34m(model, tokenizer, dataset_path, generation_args, model_type, batch_size, max_samples)\u001B[39m\n\u001B[32m     71\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m     72\u001B[39m     outputs = model(**inputs, output_hidden_states=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m     generated_ids = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mgeneration_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43meos_token_id\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     79\u001B[39m \u001B[38;5;66;03m# Декодирование ответов\u001B[39;00m\n\u001B[32m     80\u001B[39m responses = [\n\u001B[32m     81\u001B[39m     {\n\u001B[32m     82\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmodel_type\u001B[39m\u001B[33m\"\u001B[39m: model_type,\n\u001B[32m   (...)\u001B[39m\u001B[32m     97\u001B[39m     )\n\u001B[32m     98\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    113\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2465\u001B[39m, in \u001B[36mGenerationMixin.generate\u001B[39m\u001B[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001B[39m\n\u001B[32m   2457\u001B[39m     input_ids, model_kwargs = \u001B[38;5;28mself\u001B[39m._expand_inputs_for_generation(\n\u001B[32m   2458\u001B[39m         input_ids=input_ids,\n\u001B[32m   2459\u001B[39m         expand_size=generation_config.num_return_sequences,\n\u001B[32m   2460\u001B[39m         is_encoder_decoder=\u001B[38;5;28mself\u001B[39m.config.is_encoder_decoder,\n\u001B[32m   2461\u001B[39m         **model_kwargs,\n\u001B[32m   2462\u001B[39m     )\n\u001B[32m   2464\u001B[39m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2465\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2466\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2467\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2468\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2469\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2470\u001B[39m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[43m=\u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2471\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2472\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2473\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2475\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001B[32m   2476\u001B[39m     \u001B[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001B[39;00m\n\u001B[32m   2477\u001B[39m     input_ids, model_kwargs = \u001B[38;5;28mself\u001B[39m._expand_inputs_for_generation(\n\u001B[32m   2478\u001B[39m         input_ids=input_ids,\n\u001B[32m   2479\u001B[39m         expand_size=generation_config.num_beams,\n\u001B[32m   2480\u001B[39m         is_encoder_decoder=\u001B[38;5;28mself\u001B[39m.config.is_encoder_decoder,\n\u001B[32m   2481\u001B[39m         **model_kwargs,\n\u001B[32m   2482\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3434\u001B[39m, in \u001B[36mGenerationMixin._sample\u001B[39m\u001B[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[39m\n\u001B[32m   3432\u001B[39m     is_prefill = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   3433\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3434\u001B[39m     outputs = \u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   3436\u001B[39m \u001B[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001B[39;00m\n\u001B[32m   3437\u001B[39m model_kwargs = \u001B[38;5;28mself\u001B[39m._update_model_kwargs_for_generation(\n\u001B[32m   3438\u001B[39m     outputs,\n\u001B[32m   3439\u001B[39m     model_kwargs,\n\u001B[32m   3440\u001B[39m     is_encoder_decoder=\u001B[38;5;28mself\u001B[39m.config.is_encoder_decoder,\n\u001B[32m   3441\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:965\u001B[39m, in \u001B[36mcan_return_tuple.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    962\u001B[39m     set_attribute_for_modules(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m_is_top_level_module\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    964\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m965\u001B[39m     output = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    966\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_requested_to_return_tuple \u001B[38;5;129;01mor\u001B[39;00m (is_configured_to_return_tuple \u001B[38;5;129;01mand\u001B[39;00m is_top_level_module):\n\u001B[32m    967\u001B[39m         output = output.to_tuple()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001B[39m, in \u001B[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torchdynamo_compiling():\n\u001B[32m    169\u001B[39m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[32m    170\u001B[39m     warnings.warn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel=\u001B[32m2\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:821\u001B[39m, in \u001B[36mLlamaForCausalLM.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001B[39m\n\u001B[32m    816\u001B[39m output_hidden_states = (\n\u001B[32m    817\u001B[39m     output_hidden_states \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.output_hidden_states\n\u001B[32m    818\u001B[39m )\n\u001B[32m    820\u001B[39m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m821\u001B[39m outputs: BaseModelOutputWithPast = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    822\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    823\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    824\u001B[39m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    825\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    827\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    828\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    829\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    830\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    831\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    832\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    834\u001B[39m hidden_states = outputs.last_hidden_state\n\u001B[32m    835\u001B[39m \u001B[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:965\u001B[39m, in \u001B[36mcan_return_tuple.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    962\u001B[39m     set_attribute_for_modules(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m_is_top_level_module\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    964\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m965\u001B[39m     output = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    966\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_requested_to_return_tuple \u001B[38;5;129;01mor\u001B[39;00m (is_configured_to_return_tuple \u001B[38;5;129;01mand\u001B[39;00m is_top_level_module):\n\u001B[32m    967\u001B[39m         output = output.to_tuple()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:571\u001B[39m, in \u001B[36mLlamaModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001B[39m\n\u001B[32m    559\u001B[39m     layer_outputs = \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(\n\u001B[32m    560\u001B[39m         partial(decoder_layer.\u001B[34m__call__\u001B[39m, **flash_attn_kwargs),\n\u001B[32m    561\u001B[39m         hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m    568\u001B[39m         position_embeddings,\n\u001B[32m    569\u001B[39m     )\n\u001B[32m    570\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m571\u001B[39m     layer_outputs = \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    572\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    573\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    574\u001B[39m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    575\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    576\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    577\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    578\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    579\u001B[39m \u001B[43m        \u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    580\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mflash_attn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    581\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    583\u001B[39m hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    585\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:318\u001B[39m, in \u001B[36mLlamaDecoderLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001B[39m\n\u001B[32m    315\u001B[39m hidden_states = \u001B[38;5;28mself\u001B[39m.input_layernorm(hidden_states)\n\u001B[32m    317\u001B[39m \u001B[38;5;66;03m# Self Attention\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m318\u001B[39m hidden_states, self_attn_weights = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    321\u001B[39m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    322\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    323\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    324\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    325\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    326\u001B[39m \u001B[43m    \u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    327\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    328\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    329\u001B[39m hidden_states = residual + hidden_states\n\u001B[32m    331\u001B[39m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:252\u001B[39m, in \u001B[36mLlamaAttention.forward\u001B[39m\u001B[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001B[39m\n\u001B[32m    249\u001B[39m input_shape = hidden_states.shape[:-\u001B[32m1\u001B[39m]\n\u001B[32m    250\u001B[39m hidden_shape = (*input_shape, -\u001B[32m1\u001B[39m, \u001B[38;5;28mself\u001B[39m.head_dim)\n\u001B[32m--> \u001B[39m\u001B[32m252\u001B[39m query_states = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mq_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m.view(hidden_shape).transpose(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m)\n\u001B[32m    253\u001B[39m key_states = \u001B[38;5;28mself\u001B[39m.k_proj(hidden_states).view(hidden_shape).transpose(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m)\n\u001B[32m    254\u001B[39m value_states = \u001B[38;5;28mself\u001B[39m.v_proj(hidden_states).view(hidden_shape).transpose(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:484\u001B[39m, in \u001B[36mLinear4bit.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    480\u001B[39m     x = x.to(\u001B[38;5;28mself\u001B[39m.compute_dtype)\n\u001B[32m    482\u001B[39m bias = \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.bias.to(\u001B[38;5;28mself\u001B[39m.compute_dtype)\n\u001B[32m--> \u001B[39m\u001B[32m484\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbnb\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmatmul_4bit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m.\u001B[49m\u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_state\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m.\u001B[49m\u001B[43mquant_state\u001B[49m\u001B[43m)\u001B[49m.to(inp_dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:533\u001B[39m, in \u001B[36mmatmul_4bit\u001B[39m\u001B[34m(A, B, quant_state, out, bias)\u001B[39m\n\u001B[32m    531\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m out\n\u001B[32m    532\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m533\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mMatMul4Bit\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_state\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001B[39m, in \u001B[36mFunction.apply\u001B[39m\u001B[34m(cls, *args, **kwargs)\u001B[39m\n\u001B[32m    572\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch._C._are_functorch_transforms_active():\n\u001B[32m    573\u001B[39m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[32m    574\u001B[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001B[32m--> \u001B[39m\u001B[32m575\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m    577\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_setup_ctx_defined:\n\u001B[32m    578\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    579\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    580\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    581\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mstaticmethod. For more details, please see \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    582\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    583\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:462\u001B[39m, in \u001B[36mMatMul4Bit.forward\u001B[39m\u001B[34m(ctx, A, B, out, bias, quant_state)\u001B[39m\n\u001B[32m    458\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m torch.empty(A.shape[:-\u001B[32m1\u001B[39m] + B_shape[:\u001B[32m1\u001B[39m], dtype=A.dtype, device=A.device)\n\u001B[32m    460\u001B[39m \u001B[38;5;66;03m# 1. Dequantize\u001B[39;00m\n\u001B[32m    461\u001B[39m \u001B[38;5;66;03m# 2. MatmulnN\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m462\u001B[39m output = torch.nn.functional.linear(A, \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdequantize_4bit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_state\u001B[49m\u001B[43m)\u001B[49m.to(A.dtype).t(), bias)\n\u001B[32m    464\u001B[39m \u001B[38;5;66;03m# 3. Save state\u001B[39;00m\n\u001B[32m    465\u001B[39m ctx.state = quant_state\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\diplom\\venv\\Lib\\site-packages\\bitsandbytes\\functional.py:1384\u001B[39m, in \u001B[36mdequantize_4bit\u001B[39m\u001B[34m(A, quant_state, absmax, out, blocksize, quant_type)\u001B[39m\n\u001B[32m   1382\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m out.dtype == torch.float16:\n\u001B[32m   1383\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m quant_state.quant_type == \u001B[33m\"\u001B[39m\u001B[33mfp4\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1384\u001B[39m         \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcdequantize_blockwise_fp16_fp4\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1385\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1386\u001B[39m         lib.cdequantize_blockwise_fp16_nf4(*args)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T17:55:02.729736900Z",
     "start_time": "2025-05-13T17:29:19.907504Z"
    }
   },
   "cell_type": "code",
   "source": "all_activations.shape, all_labels.shape",
   "id": "f13a72aabd5b66fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 32, 4096), (2,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "best_layer, layer_scores, layers_deltas = select_best_layer(all_activations, all_labels)\n",
    "\n",
    "print(\"\\nLayers scores:\")\n",
    "for layer, score in layer_scores.items():\n",
    "    print(f\"Layer {layer}: score = {score:.4f}, delta = {layers_deltas[layer]:.4f}\")\n",
    "\n",
    "print(f\"\\nBest layer: {best_layer} with score = {layer_scores[best_layer]:.4f} delta = {layers_deltas[best_layer]:.4f}\")"
   ],
   "metadata": {
    "id": "XSnwaApF4-nR",
    "ExecuteTime": {
     "end_time": "2025-05-13T17:55:02.729736900Z",
     "start_time": "2025-05-13T17:38:12.163170Z"
    }
   },
   "id": "XSnwaApF4-nR",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layers scores:\n",
      "Layer 0: score = 0.0153, delta = 0.0000\n",
      "Layer 1: score = 0.0001, delta = -0.0152\n",
      "Layer 2: score = 0.0002, delta = 0.0001\n",
      "Layer 3: score = 0.0003, delta = 0.0001\n",
      "Layer 4: score = 0.0005, delta = 0.0002\n",
      "Layer 5: score = 0.0008, delta = 0.0002\n",
      "Layer 6: score = 0.0011, delta = 0.0003\n",
      "Layer 7: score = 0.0017, delta = 0.0006\n",
      "Layer 8: score = 0.0021, delta = 0.0005\n",
      "Layer 9: score = 0.0027, delta = 0.0006\n",
      "Layer 10: score = 0.0033, delta = 0.0006\n",
      "Layer 11: score = 0.0041, delta = 0.0009\n",
      "Layer 12: score = 0.0050, delta = 0.0009\n",
      "Layer 13: score = 0.0066, delta = 0.0016\n",
      "Layer 14: score = 0.0080, delta = 0.0014\n",
      "Layer 15: score = 0.0104, delta = 0.0023\n",
      "Layer 16: score = 0.0160, delta = 0.0057\n",
      "Layer 17: score = 0.0197, delta = 0.0037\n",
      "Layer 18: score = 0.0268, delta = 0.0071\n",
      "Layer 19: score = 0.0342, delta = 0.0074\n",
      "Layer 20: score = 0.0464, delta = 0.0122\n",
      "Layer 21: score = 0.0542, delta = 0.0078\n",
      "Layer 22: score = 0.0681, delta = 0.0139\n",
      "Layer 23: score = 0.0726, delta = 0.0045\n",
      "Layer 24: score = 0.0813, delta = 0.0087\n",
      "Layer 25: score = 0.0854, delta = 0.0041\n",
      "Layer 26: score = 0.0931, delta = 0.0077\n",
      "Layer 27: score = 0.0973, delta = 0.0042\n",
      "Layer 28: score = 0.1076, delta = 0.0104\n",
      "Layer 29: score = 0.1181, delta = 0.0105\n",
      "Layer 30: score = 0.1553, delta = 0.0372\n",
      "Layer 31: score = 0.2830, delta = 0.1277\n",
      "\n",
      "Best layer: 31 with score = 0.2830 delta = 0.1277\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d43488123e2842be"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
